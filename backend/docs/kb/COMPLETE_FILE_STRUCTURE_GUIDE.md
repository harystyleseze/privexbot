# üìÅ Complete KB File Structure & Implementation Guide

**Purpose**: Comprehensive file structure documentation with implementation details for each component

**Target Audience**: Senior engineers implementing KB features from scratch

**Status**: Production-ready structure with all required files

---

## üìã Table of Contents

1. [Overview](#overview)
2. [Backend Structure](#backend-structure)
3. [File-by-File Implementation Guide](#file-by-file-implementation-guide)
4. [Configuration Files](#configuration-files)
5. [Testing Structure](#testing-structure)
6. [Deployment Files](#deployment-files)

---

## Overview

### Complete KB System File Structure

```
privexbot/backend/
‚îú‚îÄ‚îÄ src/app/
‚îÇ   ‚îú‚îÄ‚îÄ models/                          # SQLAlchemy database models
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ knowledge_base.py            # ‚úÖ Core KB model with multi-tenancy
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ document.py                  # ‚úÖ Document model with annotations
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chunk.py                     # ‚úÖ Text chunk model
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ __init__.py                  # Model imports and registry
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ schemas/                         # Pydantic request/response schemas
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ knowledge_base.py            # ‚úÖ KB API schemas
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ document.py                  # ‚úÖ Document API schemas
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chunk.py                     # ‚úÖ Chunk API schemas
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ kb_draft.py                  # ‚úÖ Draft API schemas
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ api/v1/routes/                   # FastAPI route handlers
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ kb_draft.py                  # ‚úÖ Draft mode API endpoints
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ knowledge_bases.py           # ‚úÖ Production KB endpoints
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ documents.py                 # ‚úÖ Document management endpoints
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ search.py                    # üÜï Search and retrieval endpoints
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ services/                        # Business logic layer
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ kb_draft_service.py          # ‚úÖ Draft lifecycle management
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ document_processing_service.py # ‚úÖ Document parsing & extraction
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chunking_service.py          # ‚úÖ Intelligent text chunking
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ embedding_service.py         # ‚úÖ Self-hosted embeddings
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ vector_store_service.py      # ‚úÖ Qdrant vector operations
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ retrieval_service.py         # ‚úÖ Hybrid search & ranking
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ indexing_service.py          # üÜï Document indexing coordination
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ audit_service.py             # üÜï HIPAA/SOC2 audit logging
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ integrations/                    # External service adapters
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ unstructured_adapter.py      # üÜï Unstructured.io integration
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ crawl4ai_adapter.py          # üÜï Website crawling
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ google_docs_adapter.py       # üÜï Google Workspace integration
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ notion_adapter.py            # üÜï Notion API integration
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ qdrant_adapter.py            # üÜï Qdrant client wrapper
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ tasks/                           # Celery background tasks
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ document_tasks.py            # ‚úÖ Document processing tasks
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ embedding_tasks.py           # üÜï Batch embedding generation
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ indexing_tasks.py            # üÜï Vector indexing tasks
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cleanup_tasks.py             # üÜï Data cleanup and maintenance
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ utils/                           # Utility functions
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ file_processing.py           # üÜï File handling utilities
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ text_processing.py           # üÜï Text processing helpers
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ vector_utils.py              # üÜï Vector operation utilities
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ security_utils.py            # üÜï Security and validation helpers
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ core/                            # Core application components
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.py                    # ‚úÖ Environment configuration
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ security.py                  # ‚úÖ Authentication and security
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ logging.py                   # üÜï Structured logging setup
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ exceptions.py                # üÜï Custom exception definitions
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ db/                              # Database configuration
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base_class.py                # ‚úÖ SQLAlchemy base class
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ session.py                   # ‚úÖ Database session management
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ tests/                           # Test suite
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ unit/                        # Unit tests
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_kb_draft_service.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_document_processing.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_chunking_service.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_embedding_service.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_vector_store.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ integration/                 # Integration tests
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_kb_creation_flow.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_search_functionality.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_multi_tenancy.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ performance/                 # Performance tests
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_embedding_throughput.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_search_latency.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_concurrent_operations.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ conftest.py                  # ‚úÖ Pytest configuration
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ main.py                          # ‚úÖ FastAPI application entry point
‚îÇ
‚îú‚îÄ‚îÄ alembic/                             # Database migrations
‚îÇ   ‚îú‚îÄ‚îÄ versions/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 001_initial_kb_system.py     # üÜï KB system tables
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 002_add_document_annotations.py # üÜï Document annotations
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 003_add_vector_indexes.py    # üÜï Performance indexes
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 004_add_audit_tables.py      # üÜï Audit logging tables
‚îÇ   ‚îú‚îÄ‚îÄ alembic.ini                      # ‚úÖ Alembic configuration
‚îÇ   ‚îú‚îÄ‚îÄ env.py                           # ‚úÖ Migration environment
‚îÇ   ‚îî‚îÄ‚îÄ script.py.mako                   # ‚úÖ Migration template
‚îÇ
‚îú‚îÄ‚îÄ scripts/                             # Deployment and maintenance scripts
‚îÇ   ‚îú‚îÄ‚îÄ setup_embedding_models.py        # üÜï Download sentence-transformers models
‚îÇ   ‚îú‚îÄ‚îÄ deploy_production.sh             # üÜï Production deployment script
‚îÇ   ‚îú‚îÄ‚îÄ backup_kb_data.sh               # üÜï Backup and recovery
‚îÇ   ‚îú‚îÄ‚îÄ migrate_vector_store.py         # üÜï Vector store migration
‚îÇ   ‚îú‚îÄ‚îÄ cleanup_orphaned_data.py        # üÜï Data cleanup utilities
‚îÇ   ‚îî‚îÄ‚îÄ performance_benchmark.py        # üÜï Performance testing
‚îÇ
‚îú‚îÄ‚îÄ docs/kb/                             # Knowledge Base documentation
‚îÇ   ‚îú‚îÄ‚îÄ KB_PRODUCTION_IMPLEMENTATION_GUIDE.md      # ‚úÖ Main implementation guide
‚îÇ   ‚îú‚îÄ‚îÄ KB_PRODUCTION_IMPLEMENTATION_GUIDE_PART2.md # ‚úÖ Advanced implementation
‚îÇ   ‚îú‚îÄ‚îÄ SERVICE_ARCHITECTURE_GUIDE.md              # ‚úÖ Service patterns
‚îÇ   ‚îú‚îÄ‚îÄ COMPLETE_FILE_STRUCTURE_GUIDE.md           # ‚úÖ This document
‚îÇ   ‚îú‚îÄ‚îÄ SELF_HOSTED_INFRASTRUCTURE_GUIDE.md        # üÜï Infrastructure setup
‚îÇ   ‚îú‚îÄ‚îÄ HIPAA_SOC2_COMPLIANCE_GUIDE.md             # üÜï Compliance requirements
‚îÇ   ‚îú‚îÄ‚îÄ architecture.md                            # ‚úÖ Existing architecture overview
‚îÇ   ‚îú‚îÄ‚îÄ kb-flow.md                                 # ‚úÖ Existing KB flow documentation
‚îÇ   ‚îú‚îÄ‚îÄ kb-draft.md                                # ‚úÖ Existing draft documentation
‚îÇ   ‚îî‚îÄ‚îÄ kb_components.md                           # ‚úÖ Existing component documentation
‚îÇ
‚îú‚îÄ‚îÄ docker/                              # Docker configurations
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile.production            # üÜï Production Docker image
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile.development           # üÜï Development Docker image
‚îÇ   ‚îú‚îÄ‚îÄ docker-compose.kb-stack.yml     # üÜï Complete KB stack
‚îÇ   ‚îú‚îÄ‚îÄ docker-compose.qdrant.yml       # üÜï Qdrant vector database
‚îÇ   ‚îî‚îÄ‚îÄ docker-compose.monitoring.yml   # üÜï Monitoring stack
‚îÇ
‚îú‚îÄ‚îÄ config/                              # Configuration files
‚îÇ   ‚îú‚îÄ‚îÄ logging.conf                     # üÜï Logging configuration
‚îÇ   ‚îú‚îÄ‚îÄ celery.conf                      # üÜï Celery configuration
‚îÇ   ‚îú‚îÄ‚îÄ nginx.conf                       # üÜï Nginx reverse proxy
‚îÇ   ‚îî‚îÄ‚îÄ ssl/                             # üÜï SSL certificates directory
‚îÇ
‚îú‚îÄ‚îÄ requirements/                        # Python dependencies
‚îÇ   ‚îú‚îÄ‚îÄ base.txt                         # üÜï Core dependencies
‚îÇ   ‚îú‚îÄ‚îÄ production.txt                   # üÜï Production dependencies
‚îÇ   ‚îú‚îÄ‚îÄ development.txt                  # üÜï Development dependencies
‚îÇ   ‚îî‚îÄ‚îÄ testing.txt                      # üÜï Testing dependencies
‚îÇ
‚îú‚îÄ‚îÄ .env.production                      # üÜï Production environment variables
‚îú‚îÄ‚îÄ .env.development                     # üÜï Development environment variables
‚îú‚îÄ‚îÄ .env.example                         # ‚úÖ Environment template
‚îú‚îÄ‚îÄ pyproject.toml                       # ‚úÖ Python project configuration
‚îú‚îÄ‚îÄ Dockerfile                           # ‚úÖ Main Dockerfile
‚îú‚îÄ‚îÄ docker-compose.yml                   # ‚úÖ Development compose
‚îî‚îÄ‚îÄ README.md                            # ‚úÖ Project documentation
```

**Legend:**
- ‚úÖ = Exists with pseudocode/implementation
- üÜï = New file needed for production KB system

---

## File-by-File Implementation Guide

### Core Models

#### `src/app/models/knowledge_base.py`
```python
"""
Production KnowledgeBase model - UPDATED for production requirements.
Status: ‚úÖ Exists but needs production enhancements
"""

# ENHANCEMENTS NEEDED:
# 1. Add vector_store_config field for flexible provider support
# 2. Add context_settings for chatbot access control
# 3. Add audit fields (created_by, updated_by, etc.)
# 4. Add performance indexes
# 5. Add data retention policies

class KnowledgeBase(Base):
    __tablename__ = "knowledge_bases"

    # PRODUCTION ADDITIONS:
    vector_store_config = Column(JSONB, nullable=False, default={
        "provider": "qdrant",
        "collection_name": "",
        "distance_metric": "cosine"
    })

    context_settings = Column(JSONB, nullable=False, default={
        "access_mode": "all",
        "retrieval_config": {"top_k": 5, "threshold": 0.7}
    })

    # Performance tracking
    search_count = Column(Integer, default=0)
    last_accessed_at = Column(DateTime(timezone=True))

    # Data retention
    retention_days = Column(Integer, default=365)
    auto_delete_after = Column(DateTime(timezone=True))
```

#### `src/app/models/document.py`
```python
"""
Enhanced Document model with annotations and processing tracking.
Status: ‚úÖ Exists but needs annotation fields
"""

# ENHANCEMENTS NEEDED:
# 1. Add annotations field for AI context
# 2. Add processing_metadata for pipeline tracking
# 3. Add custom_metadata for user-defined fields
# 4. Add lifecycle management fields

class Document(Base):
    # PRODUCTION ADDITIONS:
    annotations = Column(JSONB, nullable=True, default={
        "enabled": False,
        "category": "document",
        "importance": "medium",
        "purpose": "",
        "tags": [],
        "usage_instructions": "",
        "constraints": ""
    })

    processing_metadata = Column(JSONB, nullable=False, default={})
    custom_metadata = Column(JSONB, nullable=False, default={})

    # Lifecycle management
    is_archived = Column(Boolean, default=False)
    archived_at = Column(DateTime(timezone=True))
    auto_disabled_reason = Column(String(255))
```

### New Service Files

#### `src/app/services/indexing_service.py`
```python
"""
üÜï NEW FILE: Coordinates document indexing across all components.
Purpose: Orchestrates the complete document-to-vector pipeline.
"""

class IndexingService:
    """
    Coordinates document processing, chunking, embedding, and vector storage.
    Provides a unified interface for the entire indexing pipeline.
    """

    async def index_document(self, document_id: UUID) -> IndexingResult:
        """
        Complete document indexing pipeline:
        1. Extract content (DocumentProcessingService)
        2. Generate chunks (ChunkingService)
        3. Generate embeddings (EmbeddingService)
        4. Store vectors (VectorStoreService)
        5. Update document status
        """

    async def reindex_document(self, document_id: UUID) -> IndexingResult:
        """Re-index existing document with new settings."""

    async def batch_index_documents(self, document_ids: List[UUID]) -> List[IndexingResult]:
        """Efficiently index multiple documents in parallel."""

    async def get_indexing_status(self, document_id: UUID) -> IndexingStatus:
        """Get current indexing status and progress."""
```

#### `src/app/services/audit_service.py`
```python
"""
üÜï NEW FILE: HIPAA/SOC2 compliant audit logging.
Purpose: Comprehensive audit trail for all KB operations.
"""

class AuditService:
    """
    HIPAA/SOC2 compliant audit logging for all KB operations.
    Tracks access, modifications, and administrative actions.
    """

    async def log_kb_access(self, kb_id: UUID, user_id: UUID, action: str, details: Dict):
        """Log knowledge base access events."""

    async def log_document_operation(self, doc_id: UUID, operation: str, user_id: UUID):
        """Log document CRUD operations."""

    async def log_search_activity(self, kb_id: UUID, query_hash: str, user_id: UUID):
        """Log search queries (hashed for privacy)."""

    async def log_data_export(self, resource_id: UUID, export_type: str, user_id: UUID):
        """Log data export events for compliance."""

    async def generate_audit_report(self, start_date: datetime, end_date: datetime) -> AuditReport:
        """Generate compliance audit reports."""
```

### New Integration Files

#### `src/app/integrations/unstructured_adapter.py`
```python
"""
üÜï NEW FILE: Unstructured.io integration for smart document parsing.
Purpose: Preserve document structure while extracting content.
"""

class UnstructuredAdapter:
    """
    Adapter for Unstructured.io document processing.
    Preserves tables, headings, and document structure.
    """

    async def process_document(self, file_path: str, strategy: str = "hi_res") -> ProcessingResult:
        """
        Process document using Unstructured.io:
        - Extract text with structure preservation
        - Detect and preserve tables
        - Maintain heading hierarchy
        - Extract images and charts
        """

    async def extract_tables(self, file_path: str) -> List[TableData]:
        """Extract structured table data separately."""

    async def get_document_metadata(self, file_path: str) -> DocumentMetadata:
        """Extract document metadata (author, title, etc.)."""
```

#### `src/app/integrations/qdrant_adapter.py`
```python
"""
üÜï NEW FILE: Qdrant vector database adapter.
Purpose: Optimized Qdrant operations with retry logic and performance tuning.
"""

class QdrantAdapter:
    """
    Production-ready Qdrant adapter with:
    - Connection pooling
    - Retry logic with exponential backoff
    - Batch operations optimization
    - Tenant isolation
    - Performance monitoring
    """

    async def create_collection(self, collection_name: str, vector_size: int, **config):
        """Create optimized vector collection."""

    async def upsert_vectors_batch(self, collection_name: str, vectors: List[VectorData]):
        """Batch upsert with optimal performance."""

    async def search_similar(self, collection_name: str, query_vector: List[float], **params):
        """Optimized similarity search with filtering."""

    async def get_collection_stats(self, collection_name: str) -> CollectionStats:
        """Get collection performance statistics."""
```

### New Task Files

#### `src/app/tasks/embedding_tasks.py`
```python
"""
üÜï NEW FILE: Background tasks for embedding generation.
Purpose: Process embeddings asynchronously with retry logic.
"""

@celery.task(bind=True, autoretry_for=(Exception,), retry_kwargs={'max_retries': 3})
def generate_embeddings_task(self, chunk_ids: List[str], model_name: str):
    """
    Generate embeddings for chunks in background.
    Includes retry logic and progress tracking.
    """

@celery.task(bind=True)
def batch_embed_documents_task(self, document_ids: List[str]):
    """Process multiple documents in parallel."""

@celery.task(bind=True)
def reembed_knowledge_base_task(self, kb_id: str, new_model: str):
    """Re-embed entire KB with new model."""
```

#### `src/app/tasks/cleanup_tasks.py`
```python
"""
üÜï NEW FILE: Data cleanup and maintenance tasks.
Purpose: Automated cleanup of orphaned data and old files.
"""

@celery.task
def cleanup_orphaned_vectors_task():
    """Remove vectors for deleted documents."""

@celery.task
def cleanup_expired_drafts_task():
    """Remove expired draft data from Redis."""

@celery.task
def archive_old_documents_task():
    """Archive documents based on retention policy."""

@celery.task
def compress_old_embeddings_task():
    """Compress old embedding data for storage efficiency."""
```

### New Utility Files

#### `src/app/utils/file_processing.py`
```python
"""
üÜï NEW FILE: File processing utilities.
Purpose: Secure file handling, validation, and storage.
"""

class FileProcessor:
    """Secure file processing utilities."""

    @staticmethod
    def validate_file_upload(file: UploadFile) -> ValidationResult:
        """Comprehensive file validation."""

    @staticmethod
    def secure_file_storage(file_content: bytes, filename: str, workspace_id: UUID) -> str:
        """Securely store uploaded files with encryption."""

    @staticmethod
    def extract_file_metadata(file_path: str) -> FileMetadata:
        """Extract file metadata safely."""

    @staticmethod
    def cleanup_temp_files(older_than_hours: int = 24):
        """Clean up temporary files."""
```

#### `src/app/utils/security_utils.py`
```python
"""
üÜï NEW FILE: Security utilities for KB operations.
Purpose: Input validation, sanitization, and security checks.
"""

class SecurityUtils:
    """Security utilities for KB operations."""

    @staticmethod
    def sanitize_text_input(text: str) -> str:
        """Sanitize user text input."""

    @staticmethod
    def validate_search_query(query: str) -> bool:
        """Validate search query for security."""

    @staticmethod
    def check_rate_limit(user_id: UUID, operation: str) -> bool:
        """Check operation rate limits."""

    @staticmethod
    def encrypt_sensitive_data(data: str, key: str) -> str:
        """Encrypt sensitive data for storage."""
```

### New Core Files

#### `src/app/core/logging.py`
```python
"""
üÜï NEW FILE: Structured logging configuration.
Purpose: Comprehensive logging for debugging and compliance.
"""

import logging
import json
from datetime import datetime

class StructuredLogger:
    """
    Structured logging for KB operations.
    Outputs JSON logs for easy parsing and analysis.
    """

    @staticmethod
    def setup_logging(log_level: str = "INFO"):
        """Configure structured logging."""

    @staticmethod
    def log_performance(operation: str, duration_ms: float, metadata: Dict):
        """Log performance metrics."""

    @staticmethod
    def log_error(error: Exception, context: Dict):
        """Log errors with context."""

    @staticmethod
    def log_audit_event(event_type: str, user_id: UUID, details: Dict):
        """Log audit events for compliance."""
```

#### `src/app/core/exceptions.py`
```python
"""
üÜï NEW FILE: Custom exception definitions.
Purpose: Standardized error handling across KB system.
"""

class KBException(Exception):
    """Base exception for KB operations."""
    pass

class DocumentProcessingError(KBException):
    """Document processing failed."""
    pass

class EmbeddingGenerationError(KBException):
    """Embedding generation failed."""
    pass

class VectorStoreError(KBException):
    """Vector store operation failed."""
    pass

class TenantIsolationError(KBException):
    """Tenant isolation violation."""
    pass

class ComplianceViolationError(KBException):
    """HIPAA/SOC2 compliance violation."""
    pass
```

---

## Configuration Files

### Database Migration Files

#### `alembic/versions/001_initial_kb_system.py`
```python
"""
üÜï NEW FILE: Initial KB system database schema.
Creates all tables for knowledge base functionality.
"""

def upgrade():
    # Create knowledge_bases table
    op.create_table('knowledge_bases', ...)

    # Create documents table
    op.create_table('documents', ...)

    # Create chunks table
    op.create_table('chunks', ...)

    # Create performance indexes
    op.create_index('ix_kb_workspace_status', 'knowledge_bases', ['workspace_id', 'status'])
    op.create_index('ix_documents_kb_status', 'documents', ['knowledge_base_id', 'status'])
    op.create_index('ix_chunks_document', 'chunks', ['document_id'])
```

#### `alembic/versions/004_add_audit_tables.py`
```python
"""
üÜï NEW FILE: Add audit logging tables for compliance.
"""

def upgrade():
    # Create audit_logs table
    op.create_table('audit_logs',
        sa.Column('id', postgresql.UUID(as_uuid=True), primary_key=True),
        sa.Column('event_type', sa.String(100), nullable=False),
        sa.Column('resource_type', sa.String(50), nullable=False),
        sa.Column('resource_id', postgresql.UUID(as_uuid=True)),
        sa.Column('user_id', postgresql.UUID(as_uuid=True), nullable=False),
        sa.Column('organization_id', postgresql.UUID(as_uuid=True), nullable=False),
        sa.Column('workspace_id', postgresql.UUID(as_uuid=True)),
        sa.Column('action', sa.String(100), nullable=False),
        sa.Column('details', postgresql.JSONB()),
        sa.Column('ip_address', sa.String(45)),
        sa.Column('user_agent', sa.Text()),
        sa.Column('success', sa.Boolean, nullable=False),
        sa.Column('error_message', sa.Text()),
        sa.Column('timestamp', sa.DateTime(timezone=True), server_default=func.now()),
        sa.Index('ix_audit_logs_timestamp', 'timestamp'),
        sa.Index('ix_audit_logs_user_org', 'user_id', 'organization_id'),
        sa.Index('ix_audit_logs_resource', 'resource_type', 'resource_id')
    )
```

### Docker Configuration Files

#### `docker/Dockerfile.production`
```dockerfile
# üÜï NEW FILE: Production Docker image with optimizations
FROM python:3.11-slim

# Install system dependencies
RUN apt-get update && apt-get install -y \
    build-essential \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Create non-root user for security
RUN useradd --create-home --shell /bin/bash privexbot
USER privexbot
WORKDIR /app

# Install Python dependencies
COPY requirements/production.txt requirements.txt
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY src/ src/
COPY alembic/ alembic/
COPY alembic.ini .

# Create directories for data
RUN mkdir -p /app/{models,storage,logs}

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=40s --retries=3 \
  CMD curl -f http://localhost:8000/health || exit 1

# Run application
CMD ["uvicorn", "src.app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### Python Dependency Files

#### `requirements/base.txt`
```txt
# üÜï NEW FILE: Core dependencies for KB system
fastapi==0.104.1
uvicorn[standard]==0.24.0
sqlalchemy==2.0.23
alembic==1.12.1
pydantic==2.5.0
redis==5.0.1
celery==5.3.4

# Document processing
unstructured[all]==0.11.2
sentence-transformers==2.2.2
PyMuPDF==1.23.8
python-docx==1.1.0
pandas==2.1.3
openpyxl==3.1.2

# Vector database
qdrant-client==1.7.0

# Security
passlib[bcrypt]==1.7.4
python-jose[cryptography]==3.3.0
cryptography==41.0.7

# Utilities
python-multipart==0.0.6
aiofiles==23.2.1
pillow==10.1.0
tiktoken==0.5.1
bleach==6.1.0
```

#### `requirements/production.txt`
```txt
# üÜï NEW FILE: Production-specific dependencies
-r base.txt

# Production server
gunicorn==21.2.0

# Monitoring
prometheus-client==0.19.0
structlog==23.2.0

# Performance
orjson==3.9.10
ujson==5.8.0

# Security
python-jose[cryptography]==3.3.0
passlib[bcrypt]==1.7.4
```

### Environment Configuration

#### `.env.production`
```bash
# üÜï NEW FILE: Production environment configuration
# Application
ENVIRONMENT=production
DEBUG=False
SECRET_KEY=your-super-secure-secret-key

# Database
DATABASE_URL=postgresql://privexbot:password@localhost:5432/privexbot_prod
DATABASE_POOL_SIZE=20
DATABASE_MAX_OVERFLOW=30

# Redis
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=secure_redis_password
REDIS_DB_CACHE=0
REDIS_DB_DRAFTS=1
REDIS_DB_EMBEDDINGS=2

# Qdrant
QDRANT_HOST=localhost
QDRANT_PORT=6333
QDRANT_GRPC_PORT=6334
QDRANT_API_KEY=your-qdrant-api-key

# KB Configuration
DEFAULT_EMBEDDING_MODEL=all-MiniLM-L6-v2
EMBEDDING_MODELS_PATH=/app/models
MAX_FILE_SIZE=50MB
TEMP_UPLOAD_PATH=/tmp/uploads
PERMANENT_STORAGE_PATH=/app/storage

# Celery
CELERY_BROKER_URL=redis://localhost:6379/3
CELERY_RESULT_BACKEND=redis://localhost:6379/4
CELERY_WORKER_CONCURRENCY=4

# Security & Compliance
ENABLE_AUDIT_LOGGING=true
ENCRYPT_FILES_AT_REST=true
ENCRYPTION_KEY=your-32-byte-encryption-key

# Performance
CHUNK_PROCESSING_BATCH_SIZE=100
EMBEDDING_BATCH_SIZE=32
VECTOR_UPSERT_BATCH_SIZE=100

# Monitoring
ENABLE_METRICS=true
LOG_LEVEL=INFO
```

---

## Testing Structure

### Unit Test Files

#### `src/app/tests/unit/test_chunking_service.py`
```python
"""
üÜï NEW FILE: Unit tests for chunking service.
"""

class TestChunkingService:
    """Comprehensive tests for text chunking functionality."""

    def test_recursive_chunking_strategy(self):
        """Test recursive chunking with different separators."""

    def test_by_heading_chunking(self):
        """Test heading-based chunking."""

    def test_chunk_size_limits(self):
        """Test chunk size and overlap validation."""

    def test_token_counting_accuracy(self):
        """Test token counting accuracy."""

    def test_overlap_handling(self):
        """Test chunk overlap preservation."""
```

#### `src/app/tests/integration/test_kb_creation_flow.py`
```python
"""
üÜï NEW FILE: Integration tests for complete KB creation.
"""

class TestKBCreationFlow:
    """End-to-end tests for KB creation workflow."""

    async def test_complete_kb_creation_flow(self):
        """Test entire flow from draft to production KB."""

    async def test_multi_source_kb_creation(self):
        """Test KB with multiple document sources."""

    async def test_kb_creation_with_annotations(self):
        """Test KB creation with document annotations."""

    async def test_kb_creation_failure_scenarios(self):
        """Test error handling in KB creation."""
```

### Performance Test Files

#### `src/app/tests/performance/test_search_latency.py`
```python
"""
üÜï NEW FILE: Performance tests for search operations.
"""

class TestSearchPerformance:
    """Performance tests for KB search functionality."""

    async def test_vector_search_latency(self):
        """Test vector search response times."""

    async def test_hybrid_search_performance(self):
        """Test hybrid search performance under load."""

    async def test_concurrent_search_requests(self):
        """Test system under concurrent search load."""

    async def test_large_kb_search_performance(self):
        """Test search performance with large knowledge bases."""
```

---

## Deployment Files

### Production Deployment Scripts

#### `scripts/deploy_production.sh`
```bash
#!/bin/bash
# üÜï NEW FILE: Production deployment automation

echo "üöÄ Starting KB Production Deployment"

# Prerequisites check
check_prerequisites() {
    echo "üìã Checking prerequisites..."
    # Check Docker, Docker Compose, environment files
}

# Download and cache embedding models
setup_embedding_models() {
    echo "ü§ñ Setting up embedding models..."
    python3 scripts/setup_embedding_models.py
}

# Start infrastructure services
start_infrastructure() {
    echo "üîß Starting infrastructure services..."
    docker-compose -f docker/docker-compose.qdrant.yml up -d
    # Wait for readiness checks
}

# Run database migrations
run_migrations() {
    echo "üóÑÔ∏è Running database migrations..."
    cd src && alembic upgrade head && cd ..
}

# Deploy application
deploy_application() {
    echo "üöÄ Deploying application..."
    docker-compose -f docker/docker-compose.production.yml up -d
}

# Verify deployment
verify_deployment() {
    echo "üè• Running health checks..."
    # Test all endpoints and services
}

# Main deployment flow
main() {
    check_prerequisites
    setup_embedding_models
    start_infrastructure
    run_migrations
    deploy_application
    verify_deployment
    echo "‚úÖ Deployment complete!"
}

main "$@"
```

This comprehensive file structure guide provides the complete blueprint for implementing a production-ready knowledge base system. Each file has a clear purpose and implementation guidance, ensuring consistent architecture across the entire system.

<function_calls>
<invoke name="TodoWrite">
<parameter name="todos">[{"content": "Create complete file/folder structure documentation", "status": "completed", "activeForm": "Creating complete file/folder structure documentation"}, {"content": "Create self-hosted infrastructure setup guide", "status": "in_progress", "activeForm": "Creating self-hosted infrastructure setup guide"}, {"content": "Review and validate existing KB pseudocodes for accuracy", "status": "pending", "activeForm": "Reviewing and validating existing KB pseudocodes"}, {"content": "Create HIPAA/SOC2 compliance documentation", "status": "pending", "activeForm": "Creating HIPAA/SOC2 compliance documentation"}, {"content": "Create deployment verification checklist", "status": "pending", "activeForm": "Creating deployment verification checklist"}]