"""add_knowledge_base_document_chunk_models_with_pgvector

Revision ID: 890e849f1044
Revises: 2388518a8727
Create Date: 2025-11-16 03:04:54.012704

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql
import pgvector.sqlalchemy

# revision identifiers, used by Alembic.
revision: str = '890e849f1044'
down_revision: Union[str, Sequence[str], None] = '2388518a8727'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('knowledge_bases',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('name', sa.String(length=255), nullable=False),
    sa.Column('description', sa.Text(), nullable=True),
    sa.Column('workspace_id', sa.UUID(), nullable=False),
    sa.Column('status', sa.String(length=50), nullable=False),
    sa.Column('config', postgresql.JSONB(astext_type=sa.Text()), nullable=False),
    sa.Column('context_settings', postgresql.JSONB(astext_type=sa.Text()), nullable=False),
    sa.Column('embedding_config', postgresql.JSONB(astext_type=sa.Text()), nullable=False),
    sa.Column('vector_store_config', postgresql.JSONB(astext_type=sa.Text()), nullable=False),
    sa.Column('indexing_method', sa.String(length=50), nullable=False),
    sa.Column('reindex_required', sa.Boolean(), nullable=False),
    sa.Column('total_documents', sa.Integer(), nullable=False),
    sa.Column('total_chunks', sa.Integer(), nullable=False),
    sa.Column('total_tokens', sa.Integer(), nullable=False),
    sa.Column('last_indexed_at', sa.DateTime(), nullable=True),
    sa.Column('processed_at', sa.DateTime(), nullable=True),
    sa.Column('error_message', sa.Text(), nullable=True),
    sa.Column('stats', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.Column('created_by', sa.UUID(), nullable=False),
    sa.Column('created_at', sa.DateTime(), nullable=False),
    sa.Column('updated_at', sa.DateTime(), nullable=False),
    sa.ForeignKeyConstraint(['created_by'], ['users.id'], ),
    sa.ForeignKeyConstraint(['workspace_id'], ['workspaces.id'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_knowledge_bases_status'), 'knowledge_bases', ['status'], unique=False)
    op.create_index(op.f('ix_knowledge_bases_workspace_id'), 'knowledge_bases', ['workspace_id'], unique=False)
    op.create_table('documents',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('kb_id', sa.UUID(), nullable=False),
    sa.Column('workspace_id', sa.UUID(), nullable=False),
    sa.Column('name', sa.String(length=500), nullable=False),
    sa.Column('source_type', sa.String(length=50), nullable=False),
    sa.Column('source_url', sa.String(length=2048), nullable=True),
    sa.Column('source_metadata', postgresql.JSONB(astext_type=sa.Text()), nullable=False),
    sa.Column('file_path', sa.String(length=1024), nullable=True),
    sa.Column('content_preview', sa.Text(), nullable=True),
    sa.Column('status', sa.String(length=50), nullable=False),
    sa.Column('processing_progress', sa.Integer(), nullable=False),
    sa.Column('error_message', sa.Text(), nullable=True),
    sa.Column('processing_metadata', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.Column('word_count', sa.Integer(), nullable=False),
    sa.Column('character_count', sa.Integer(), nullable=False),
    sa.Column('page_count', sa.Integer(), nullable=True),
    sa.Column('chunk_count', sa.Integer(), nullable=False),
    sa.Column('custom_metadata', postgresql.JSONB(astext_type=sa.Text()), nullable=False),
    sa.Column('chunking_config', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.Column('annotations', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.Column('is_enabled', sa.Boolean(), nullable=False),
    sa.Column('is_archived', sa.Boolean(), nullable=False),
    sa.Column('disabled_at', sa.DateTime(), nullable=True),
    sa.Column('archived_at', sa.DateTime(), nullable=True),
    sa.Column('auto_disabled_reason', sa.Text(), nullable=True),
    sa.Column('created_by', sa.UUID(), nullable=False),
    sa.Column('created_at', sa.DateTime(), nullable=False),
    sa.Column('updated_at', sa.DateTime(), nullable=False),
    sa.Column('last_accessed_at', sa.DateTime(), nullable=True),
    sa.ForeignKeyConstraint(['created_by'], ['users.id'], ),
    sa.ForeignKeyConstraint(['kb_id'], ['knowledge_bases.id'], ondelete='CASCADE'),
    sa.ForeignKeyConstraint(['workspace_id'], ['workspaces.id'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_documents_kb_id'), 'documents', ['kb_id'], unique=False)
    op.create_index(op.f('ix_documents_source_type'), 'documents', ['source_type'], unique=False)
    op.create_index(op.f('ix_documents_status'), 'documents', ['status'], unique=False)
    op.create_index(op.f('ix_documents_workspace_id'), 'documents', ['workspace_id'], unique=False)
    op.create_table('chunks',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('document_id', sa.UUID(), nullable=False),
    sa.Column('kb_id', sa.UUID(), nullable=False),
    sa.Column('content', sa.Text(), nullable=False),
    sa.Column('content_hash', sa.String(length=64), nullable=True),
    sa.Column('position', sa.Integer(), nullable=False),
    sa.Column('chunk_index', sa.Integer(), nullable=False),
    sa.Column('page_number', sa.Integer(), nullable=True),
    sa.Column('chunk_metadata', postgresql.JSONB(astext_type=sa.Text()), nullable=False),
    sa.Column('word_count', sa.Integer(), nullable=False),
    sa.Column('character_count', sa.Integer(), nullable=False),
    sa.Column('token_count', sa.Integer(), nullable=True),
    sa.Column('embedding', pgvector.sqlalchemy.vector.VECTOR(dim=384), nullable=True),
    sa.Column('embedding_id', sa.String(length=255), nullable=True),
    sa.Column('embedding_metadata', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.Column('keywords', postgresql.ARRAY(sa.String()), nullable=True),
    sa.Column('is_enabled', sa.Boolean(), nullable=False),
    sa.Column('is_edited', sa.Boolean(), nullable=False),
    sa.Column('quality_score', sa.Float(), nullable=True),
    sa.Column('created_at', sa.DateTime(), nullable=False),
    sa.Column('updated_at', sa.DateTime(), nullable=False),
    sa.Column('last_retrieved_at', sa.DateTime(), nullable=True),
    sa.Column('retrieval_count', sa.Integer(), nullable=False),
    sa.ForeignKeyConstraint(['document_id'], ['documents.id'], ondelete='CASCADE'),
    sa.ForeignKeyConstraint(['kb_id'], ['knowledge_bases.id'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_chunks_content_hash'), 'chunks', ['content_hash'], unique=False)
    op.create_index(op.f('ix_chunks_document_id'), 'chunks', ['document_id'], unique=False)
    op.create_index(op.f('ix_chunks_is_enabled'), 'chunks', ['is_enabled'], unique=False)
    op.create_index(op.f('ix_chunks_kb_id'), 'chunks', ['kb_id'], unique=False)
    op.create_index(op.f('ix_chunks_position'), 'chunks', ['position'], unique=False)
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_chunks_position'), table_name='chunks')
    op.drop_index(op.f('ix_chunks_kb_id'), table_name='chunks')
    op.drop_index(op.f('ix_chunks_is_enabled'), table_name='chunks')
    op.drop_index(op.f('ix_chunks_document_id'), table_name='chunks')
    op.drop_index(op.f('ix_chunks_content_hash'), table_name='chunks')
    op.drop_table('chunks')
    op.drop_index(op.f('ix_documents_workspace_id'), table_name='documents')
    op.drop_index(op.f('ix_documents_status'), table_name='documents')
    op.drop_index(op.f('ix_documents_source_type'), table_name='documents')
    op.drop_index(op.f('ix_documents_kb_id'), table_name='documents')
    op.drop_table('documents')
    op.drop_index(op.f('ix_knowledge_bases_workspace_id'), table_name='knowledge_bases')
    op.drop_index(op.f('ix_knowledge_bases_status'), table_name='knowledge_bases')
    op.drop_table('knowledge_bases')
    # ### end Alembic commands ###
